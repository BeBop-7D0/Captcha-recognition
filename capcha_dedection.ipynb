{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Decoding captcha",
   "id": "a74af2f299272bf3"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "Importing the required libraries",
   "id": "eb4bf74b196790ec"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras import api\n",
    "from keras.api import layers\n",
    "from keras.api.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2 as cv\n",
    "import sklearn"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "Loading data (5 character captcha).",
   "id": "f355662038498879"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "file_names = os.listdir('D://kapchi//dataset//dataset')\n",
    "y_s = [f.split('.')[0] for f in file_names] # Vector of answers to captchas\n",
    "data = []\n",
    "for i in range(len(file_names)):\n",
    "    if len(file_names[i].split('.')[0]) == 5:\n",
    "        img = (Image.open('D://kapchi//dataset//dataset//' + file_names[i]).convert('L'))\n",
    "        data.append([np.asarray(img) / 255, y_s[i]])  # We represent the captcha as a normalized, single-channel image, stretched into a vector.\n",
    "np.random.shuffle(data)\n",
    "x, y = [], []\n",
    "for elem in data:\n",
    "    x.append(elem[0]) # Vector x is a vector whose elements correspond to the vector representation of each image\n",
    "    y.append(elem[1]) # Vector y is a vector whose elements correspond to the decryption of each captcha.\n",
    "n_elem = len(x)\n",
    "print(n_elem)"
   ],
   "id": "4b3c78cebbfa0b74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "We form test and training samples(train - 7000 elems, test- 2853).",
   "id": "16b4e456ccc542f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_train = np.expand_dims(np.array(x[:7000]), axis=3)\n",
    "y_train = np.array(y[:7000])\n",
    "x_test = np.expand_dims(np.array(x[7000:]), axis=3)\n",
    "y_test = np.array(y[7000:])\n",
    "print(len(x_test))"
   ],
   "id": "f146783f3c2640ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "We bring the answer vector to a categorical form. The output is a tensor with dimension (5 x 2853 x 76) and (5 x 7000 x 76).\n",
    "The categories are as follows: [0 0 0 ... 0 1 0 0 ...], [0 1 0 ... 0 0 0..] etc."
   ],
   "id": "810f3a37b5c0fd44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "letters = 'ёйцукенгшщзхъфывапролджэячсмитьбю' + 'ёйцукенгшщзхъфывапролджэячсмитьбю'.upper() + '0123456789'\n",
    "letters_chars = [ord(l) for l in letters]\n",
    "y_train_cat = np.array([[api.utils.to_categorical(letters.find(elem[i]), len(letters_chars)) for elem in y_train] for i in range(5)])\n",
    "y_test_cat = np.array([[api.utils.to_categorical(letters.find(elem[i]), len(letters_chars)) for elem in y_test] for i in range(5)])"
   ],
   "id": "de121ac6176a03b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Network architecture",
   "id": "6f717637e90c1ed4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_model():\n",
    "    img = layers.Input(shape=(60, 200, 1))\n",
    "    conv1 = layers.Conv2D(16, (3, 3), padding='same', activation='relu')(img) # Convolution1(input(60x200x1), output(60x200x16))\n",
    "    mp1 = layers.MaxPooling2D(padding='same')(conv1)                          # pooling1(input(60x200x16), output(30x100x16))\n",
    "    conv2 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(mp1) # Convolution2(input(30x100x16), output(30x100x32))\n",
    "    mp2 = layers.MaxPooling2D(padding='same')(conv2)                          # pooling2(input(30x100x32), output(15x50x32))\n",
    "    conv3 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(mp2) # Convolution3(input(15x50x32), output(15x50x32))\n",
    "    bn = layers.BatchNormalization()(conv3)                                   # Batch_norm\n",
    "    mp3 = layers.MaxPooling2D(padding='same')(bn)                             # pooling3(input(15x50x32), output(8x25x32))\n",
    "    flat = layers.Flatten()(mp3)                                              # flatten(input(8x25x32), output(6400))\n",
    "    \n",
    "    outs = []\n",
    "    for _ in range(5):                                                        # form five output layers\n",
    "        dens1 = layers.Dense(64, activation='relu')(flat)                     # Dense[1, 2, 3, 4, 5](input(6400), output(64))\n",
    "        dr = layers.Dropout(0.6)(dens1)                                       # Dropout(60%)\n",
    "        res = layers.Dense(76, activation='softmax')(dr)                      # Dense[1, 2, 3, 4, 5](input(64), output(76)-> softmax)\n",
    "        \n",
    "        outs.append(res)\n",
    "    model = api.Model(img, outs)\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                  metrics=[[\"accuracy\"],[\"accuracy\"],[\"accuracy\"],[\"accuracy\"],[\"accuracy\"]])\n",
    "    return model\n"
   ],
   "id": "e4464e7802136bf8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ],
   "id": "b49882144edcbccf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " # Training the model",
   "id": "83bb32e4eb606acd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "hist = model.fit(x_train, [y_train_cat[0], y_train_cat[1], y_train_cat[2], y_train_cat[3], y_train_cat[4]], validation_split=0.3, batch_size=50, epochs=60)",
   "id": "c9a74d894b52dc23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Graphs",
   "id": "b99a1466129d1d7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Graph of the change in the loss function on training and validation data.\n",
    "Graph of the change in the \"accuracy\" metric for the first output of the model."
   ],
   "id": "11c9dc2f799a125c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist.history['loss'], color='blue')\n",
    "plt.plot(hist.history['val_loss'], color='black')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(('loss','val_loss'))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist.history['dense_111_accuracy'], color='blue')\n",
    "plt.plot(hist.history['val_dense_111_accuracy'], color='black')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(('accuracy','val_accuracy'))\n",
    "plt.show()"
   ],
   "id": "e48b99f53ad37916",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Testing",
   "id": "6f4746f0cbf792a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Checking the model's performance on a test and train samples.",
   "id": "dbf506e982b258bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pred_train = model.evaluate(x_train, [y_train_cat[0], y_train_cat[1],y_train_cat[2],y_train_cat[3],y_train_cat[4]])\n",
    "pred_test = model.evaluate(x_test , [y_test_cat[0], y_test_cat[1],y_test_cat[2],y_test_cat[3],y_test_cat[4]])\n",
    "print(f'loss on training data= {pred_train[0]}')\n",
    "print(f\"loss on testing data= {pred_test[0]}\")"
   ],
   "id": "ea22ce200812ee84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We are forming a list of answers (predict)",
   "id": "520dac0fa2101004"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_result(x, i):\n",
    "    return ''.join([letters[np.argmax(x[j][i])] for j in range(5)])\n",
    "predict = np.array(model.predict(x_test))\n",
    "predict = np.array([get_result(predict, i) for i in range(predict.shape[1])])"
   ],
   "id": "7bc91dd7837d664b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Number of correct and incorrect classifications",
   "id": "b2ff694ba5defb3a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mask = y_test == predict\n",
    "x_correct = x_test[mask]\n",
    "y_correct = predict[mask]\n",
    "x_incorrect = x_test[~mask]\n",
    "y_incorrect = predict[~mask]\n",
    "answ = y_test[~mask]\n",
    "print(f\"number of correct classifications = {len(x_correct)}\")\n",
    "print(f\"number of incorrect classifications = {len(x_incorrect)}\")\n"
   ],
   "id": "8b6c0d5412ddece9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Images of 4 correct classifications",
   "id": "8859a86d469f697d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(1, 5):\n",
    "    plt.subplot(2, 2, i)\n",
    "    plt.imshow(x_correct[i-1], cmap=plt.cm.binary)\n",
    "    plt.title(f\"predict={y_correct[i-1]}\")\n"
   ],
   "id": "7cba6edcdab5dfb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Images of 4 incorrect classifications",
   "id": "f209fdffc4c5aaed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(1, 5):\n",
    "    plt.subplot(2, 2, i)\n",
    "    plt.imshow(x_incorrect[i-1], cmap=plt.cm.binary)\n",
    "    plt.title(f\"predict={y_incorrect[i-1]}, answer={answ[i-1]}\")\n"
   ],
   "id": "3cda58673bfea85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save model",
   "id": "560b67722a2a5e77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_name = 'CaptchaDecoder.h5'\n",
    "MODELS_DIR = 'D:\\work\\project2\\pythonProject'\n",
    "# Save model and weights\n",
    "if not os.path.isdir(MODELS_DIR):\n",
    "    os.makedirs(MODELS_DIR)\n",
    "model_path = os.path.join(MODELS_DIR, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ],
   "id": "987269597aa4a52d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a03e41074d98da4b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
